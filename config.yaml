# Configuration file for Flow Shop algorithms

# General settings
general:
  # input_file: "data/tai20_5.txt"
  # input_file: "data/tai20_10.txt"
  # input_file: "data/tai20_20.txt"

  # input_file: "data/tai50_5.txt"
  # input_file: "data/tai50_10.txt"
  # input_file: "data/tai50_20.txt"

  # input_file: "data/tai100_5.txt"
  # input_file: "data/tai100_10.txt"
  # input_file: "data/tai100_20.txt"

# Od tad lepsiejsze
  # input_file: "data/tai200_10.txt"
  # input_file: "data/tai200_20.txt"

  input_file: "data/tai500_20.txt"
  instance_number: 2
  # Choose exactly one compare mode:
  # - "tabu_search_compare"
  # - "simulated_annealing_compare"
  algorithm: "tabu_search_compare"
  # algorithm: "simulated_annealing_compare"


visualization:
  save_plots: true
  results_folder: "results"

algorithm_common:
  # Time limit can be specified in seconds (recommended) or milliseconds.
  time_limit_s: 100

tabu_search:
  tabu_tenure: 10

simulated_annealing:
  initial_temp: 1000.0
  final_temp: 1.0
  alpha: 0.95
  # Time-based reheating parameters (restored 2025-10-05)
  reheat_factor: 1.5          # multiply temperature by this on stagnation (capped at initial_temp)
  stagnation_ms: 5000         # no improvement for this many ms -> attempt reheat
  temp_floor_factor: 1.0      # floor = final_temp * factor (>=1)

# Optional generator: if provided, `main.py` will generate a synthetic instance
# instead of reading from `general.input_file`.
generator:
  enabled: false
  # number of machines
  m: 20
  # number of jobs
  n: 700
  # RNG seed for reproducibility
  seed: 42
  # Taillard-only generator (no low/high)
  # type is fixed to 'taillard'

# Experiment batch mode (new)
experiment:
  enabled: false  
  tabu_tenure: 10   
      # when true: run batch experiments (all instances); false -> compare mode
  # instance_files: [
  #   "data/tai20_5.txt", "data/tai20_10.txt", "data/tai20_20.txt",
  #   "data/tai50_5.txt", "data/tai50_10.txt", "data/tai50_20.txt",
  #   "data/tai100_5.txt", "data/tai100_10.txt", "data/tai100_20.txt",
  #   "data/tai200_10.txt", "data/tai200_20.txt",
  #   "data/tai500_20.txt"
  # ]
  # repeats: 1             # number of RNG seeds per (algorithm, neighborhood, instance, time_limit)
  # time_limits_s: [0.1, 1, 10]


  instance_files: [
    # "data/tai20_5.txt",
    # "data/tai50_20.txt",
    # "data/tai100_5.txt", 
    "data/tai200_20.txt",
    # "data/tai500_20.txt"
  ]
  repeats: 1             # number of RNG seeds per (algorithm, neighborhood, instance, time_limit)
  # time_limits_s: [0.1, 1, 10]
  time_limits_s: [1]

